#!/usr/bin/env python
"""
Playwright å›¾ç‰‡ä¸‹è½½æµ‹è¯•ã€‚

æµ‹è¯• Playwright çˆ¬è™«æ˜¯å¦èƒ½å¤ŸçœŸæ­£ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°ã€‚
å›¾ç‰‡å°†ä¿å­˜åœ¨ tests/downloaded_images/ ç›®å½•ä¸­ã€‚
"""

import asyncio
import os
import sys
from datetime import datetime
from pathlib import Path
from playwright.async_api import async_playwright
import httpx


# åˆ›å»ºä¿å­˜ç›®å½•
SAVE_DIR = Path(__file__).parent / "downloaded_images"
SAVE_DIR.mkdir(exist_ok=True)


async def download_image(url: str, save_path: Path) -> bool:
    """
    ä¸‹è½½å•å¼ å›¾ç‰‡ã€‚
    
    Args:
        url: å›¾ç‰‡ URL
        save_path: ä¿å­˜è·¯å¾„
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(url, follow_redirects=True)
            
            if response.status_code == 200:
                save_path.write_bytes(response.content)
                size_kb = len(response.content) / 1024
                print(f"   âœ… ä¸‹è½½æˆåŠŸ: {save_path.name} ({size_kb:.1f} KB)")
                return True
            else:
                print(f"   âŒ ä¸‹è½½å¤±è´¥: {url} (çŠ¶æ€ç : {response.status_code})")
                return False
                
    except Exception as e:
        print(f"   âŒ ä¸‹è½½å¼‚å¸¸: {url} ({e})")
        return False


async def test_playwright_image_crawler():
    """æµ‹è¯• Playwright çˆ¬å–å¹¶ä¸‹è½½å›¾ç‰‡ã€‚"""
    print("\n" + "="*70)
    print("Playwright å›¾ç‰‡çˆ¬å–å’Œä¸‹è½½æµ‹è¯•")
    print("="*70 + "\n")
    
    print(f"ğŸ“ å›¾ç‰‡å°†ä¿å­˜åˆ°: {SAVE_DIR.absolute()}\n")
    
    # æœç´¢é…ç½®
    search_query = "é¥æ„Ÿå½±åƒ"
    max_images = 5  # é™åˆ¶æ•°é‡ä»¥ä¾¿å¿«é€Ÿæµ‹è¯•
    
    print(f"ğŸ” æœç´¢å…³é”®è¯: {search_query}")
    print(f"ğŸ“Š ç›®æ ‡æ•°é‡: {max_images} å¼ \n")
    
    try:
        print("1ï¸âƒ£  å¯åŠ¨æµè§ˆå™¨...")
        async with async_playwright() as p:
            # å¯åŠ¨æµè§ˆå™¨ï¼ˆæ— å¤´æ¨¡å¼ï¼‰
            browser = await p.chromium.launch(
                headless=True,  # è®¾ç½®ä¸º False å¯ä»¥çœ‹åˆ°æµè§ˆå™¨
                args=['--disable-blink-features=AutomationControlled']
            )
            print("   âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ\n")
            
            # åˆ›å»ºé¡µé¢
            page = await browser.new_page()
            
            # è®¾ç½® User-Agent
            await page.set_extra_http_headers({
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            })
            
            # è®¿é—®å¿…åº”å›¾ç‰‡æœç´¢
            print("2ï¸âƒ£  è®¿é—®å¿…åº”å›¾ç‰‡æœç´¢...")
            search_url = f"https://www.bing.com/images/search?q={search_query}&first=1"
            
            await page.goto(search_url, wait_until="networkidle", timeout=15000)
            print("   âœ… é¡µé¢åŠ è½½æˆåŠŸ\n")
            
            # ç­‰å¾…å›¾ç‰‡åŠ è½½
            print("3ï¸âƒ£  ç­‰å¾…å›¾ç‰‡åŠ è½½...")
            try:
                await page.wait_for_selector("img.mimg", timeout=10000)
                print("   âœ… å›¾ç‰‡å…ƒç´ å·²åŠ è½½\n")
            except Exception as e:
                print(f"   âš ï¸  ç­‰å¾…å›¾ç‰‡è¶…æ—¶: {e}\n")
            
            # è·å–å›¾ç‰‡ä¿¡æ¯
            print("4ï¸âƒ£  æå–å›¾ç‰‡ä¿¡æ¯...")
            image_elements = await page.query_selector_all("img.mimg")
            print(f"   âœ… æ‰¾åˆ° {len(image_elements)} å¼ å›¾ç‰‡\n")
            
            # æå–å›¾ç‰‡ URL
            print("5ï¸âƒ£  æå–å›¾ç‰‡ URL...")
            image_urls = []
            
            for i, img in enumerate(image_elements[:max_images], 1):
                src = await img.get_attribute("src")
                
                if src and (src.startswith("http") or src.startswith("https")):
                    image_urls.append(src)
                    print(f"   å›¾ç‰‡ {i}: {src[:60]}...")
            
            print(f"\n   âœ… æˆåŠŸæå– {len(image_urls)} ä¸ªæœ‰æ•ˆ URL\n")
            
            # å…³é—­æµè§ˆå™¨
            await browser.close()
            print("   âœ… æµè§ˆå™¨å·²å…³é—­\n")
        
        # ä¸‹è½½å›¾ç‰‡
        print("6ï¸âƒ£  ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°...")
        print(f"   ä¿å­˜ç›®å½•: {SAVE_DIR.absolute()}\n")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        successful_downloads = 0
        
        for i, url in enumerate(image_urls, 1):
            # æ„å»ºä¿å­˜è·¯å¾„
            extension = ".jpg"  # é»˜è®¤æ‰©å±•å
            if ".png" in url:
                extension = ".png"
            elif ".webp" in url:
                extension = ".webp"
            
            filename = f"{search_query}_{timestamp}_{i:02d}{extension}"
            save_path = SAVE_DIR / filename
            
            print(f"   ä¸‹è½½å›¾ç‰‡ {i}/{len(image_urls)}...")
            success = await download_image(url, save_path)
            
            if success:
                successful_downloads += 1
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            await asyncio.sleep(0.5)
        
        # è¾“å‡ºç»“æœ
        print("\n" + "="*70)
        print("ğŸ“Š æµ‹è¯•ç»“æœ")
        print("="*70)
        print(f"\nâœ… çˆ¬å–æˆåŠŸ: æ‰¾åˆ° {len(image_urls)} å¼ å›¾ç‰‡")
        print(f"âœ… ä¸‹è½½æˆåŠŸ: {successful_downloads}/{len(image_urls)} å¼ å›¾ç‰‡")
        print(f"\nğŸ“ ä¿å­˜ä½ç½®: {SAVE_DIR.absolute()}")
        
        # åˆ—å‡ºä¸‹è½½çš„æ–‡ä»¶
        if successful_downloads > 0:
            print(f"\nğŸ“‹ å·²ä¸‹è½½çš„æ–‡ä»¶:")
            for file in sorted(SAVE_DIR.glob(f"{search_query}_{timestamp}_*")):
                size_kb = file.stat().st_size / 1024
                print(f"   - {file.name} ({size_kb:.1f} KB)")
        
        print("\n" + "="*70)
        print("ğŸ‰ Playwright å›¾ç‰‡çˆ¬å–å’Œä¸‹è½½æµ‹è¯•æˆåŠŸï¼")
        print("="*70 + "\n")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        print("\nğŸ’¡ æ•…éšœæ’æŸ¥ï¼š")
        print("   1. ç¡®ä¿å·²å®‰è£… Playwright: poetry run playwright install")
        print("   2. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   3. ç¡®è®¤é˜²ç«å¢™è®¾ç½®")
        print("   4. å°è¯•ä½¿ç”¨ headless=False æŸ¥çœ‹æµè§ˆå™¨è¡Œä¸º\n")
        
        return False


async def clean_old_images(days_old: int = 7):
    """
    æ¸…ç†æ—§å›¾ç‰‡ã€‚
    
    Args:
        days_old: åˆ é™¤å¤šå°‘å¤©å‰çš„å›¾ç‰‡
    """
    import time
    
    if not SAVE_DIR.exists():
        return
    
    now = time.time()
    cutoff = now - (days_old * 86400)
    
    for file in SAVE_DIR.glob("*"):
        if file.is_file() and file.stat().st_mtime < cutoff:
            file.unlink()
            print(f"   ğŸ—‘ï¸  åˆ é™¤æ—§æ–‡ä»¶: {file.name}")


if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          Playwright å›¾ç‰‡çˆ¬å–å’Œä¸‹è½½æµ‹è¯•                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

è¿™ä¸ªæµ‹è¯•ä¼šï¼š
  âœ“ å¯åŠ¨ Playwright æµè§ˆå™¨
  âœ“ è®¿é—®å¿…åº”å›¾ç‰‡æœç´¢
  âœ“ æœç´¢"é¥æ„Ÿå½±åƒ"
  âœ“ æå–å›¾ç‰‡ URL
  âœ“ ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°
  âœ“ æ˜¾ç¤ºä¿å­˜ä½ç½®

""")
    
    try:
        # æ¸…ç†æ—§å›¾ç‰‡
        asyncio.run(clean_old_images(days_old=7))
        
        # è¿è¡Œæµ‹è¯•
        result = asyncio.run(test_playwright_image_crawler())
        sys.exit(0 if result else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)

